{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAd7BtyUmQb3"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8mFcbSyhj0Ag"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dc0LR5kpmFte"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/FinallyLemmas.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u4qVSXDej4Nf"
      },
      "outputs": [],
      "source": [
        "num_classes=df.label.unique()\n",
        "num_classes=num_classes.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OSOtv3Lrmd6E"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns='label')\n",
        "y = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DIC3nDillJe0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.10, random_state=42) # 10% testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5b4jcxnqBeV",
        "outputId": "b2a0990d-8ad6-4fe2-c11a-d6dfad972bda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length:  6148\n"
          ]
        }
      ],
      "source": [
        "# encoded_tweets = [tokenizer.encode((sent), add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "\n",
        "# # Find the maximum length\n",
        "# max_len = max([len(sent) for sent in encoded_tweets])\n",
        "# print('Max length: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "E_DZd7QTq3QK"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y_train, test_size=0.15, random_state=42) # validation 13.5%, Training around 76%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AfaRJ66Cj5Zo"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34h8HzTOj71h",
        "outputId": "5790c4a4-c450-4f9a-a083-445fe3637828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "216914"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrQn76-NjOKo",
        "outputId": "83a174f9-2939-4285-b196-41cabafc1eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length:  700\n"
          ]
        }
      ],
      "source": [
        "max_len = 700\n",
        "print('Max length: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "21VDHZ4CAx6k"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y37Gwu4pjONX"
      },
      "outputs": [],
      "source": [
        "dff=shuffle(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r54oY2bHjOVM"
      },
      "outputs": [],
      "source": [
        "num_classes=dff.label.unique()\n",
        "num_classes=num_classes.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FHiMrfb3jOWY"
      },
      "outputs": [],
      "source": [
        "X = dff.drop(columns='label')\n",
        "y = dff['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j5SlZtSqjOXl"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.10, random_state=42) # 10% Testing, 13.5% validation, 76% Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-4HQ50P5jOb2"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train.lemmaText)\n",
        "X = tokenizer.texts_to_sequences(X_train.lemmaText)\n",
        "X = pad_sequences(X, maxlen=700)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EJR6VUt0F5Po"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y_train, test_size=0.15, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MtuD1WBF_Iq",
        "outputId": "04ec4186-3013-4a27-ed70-5932e5677f37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "216598"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nb77iIxGAdd",
        "outputId": "d7fdd421-e97f-4b8a-bf9a-240f12e507d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1388/1388 [==============================] - 271s 192ms/step - loss: 0.9711 - accuracy: 0.6812 - val_loss: 0.4718 - val_accuracy: 0.8691\n",
            "Epoch 2/10\n",
            "1388/1388 [==============================] - 126s 91ms/step - loss: 0.2677 - accuracy: 0.9221 - val_loss: 0.2777 - val_accuracy: 0.9268\n",
            "Epoch 3/10\n",
            "1388/1388 [==============================] - 98s 70ms/step - loss: 0.1445 - accuracy: 0.9593 - val_loss: 0.1994 - val_accuracy: 0.9442\n",
            "Epoch 4/10\n",
            "1388/1388 [==============================] - 78s 56ms/step - loss: 0.0728 - accuracy: 0.9801 - val_loss: 0.1933 - val_accuracy: 0.9480\n",
            "Epoch 5/10\n",
            "1388/1388 [==============================] - 79s 57ms/step - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.1894 - val_accuracy: 0.9551\n",
            "Epoch 6/10\n",
            "1388/1388 [==============================] - 74s 53ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.2103 - val_accuracy: 0.9526\n",
            "Epoch 7/10\n",
            "1388/1388 [==============================] - 72s 52ms/step - loss: 0.0134 - accuracy: 0.9966 - val_loss: 0.2139 - val_accuracy: 0.9547\n",
            "Epoch 8/10\n",
            "1388/1388 [==============================] - 70s 50ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.2852 - val_accuracy: 0.9362\n",
            "Epoch 9/10\n",
            "1388/1388 [==============================] - 69s 49ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.2310 - val_accuracy: 0.9538\n",
            "Epoch 10/10\n",
            "1388/1388 [==============================] - 78s 56ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.2361 - val_accuracy: 0.9512\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=700))\n",
        "model.add(LSTM(units=256))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "num_epochs = 10  \n",
        "batch_size = 32  \n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiqrifFSJz-A",
        "outputId": "58df0128-44cd-444e-8253-bf7c42bf60f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "182/182 [==============================] - 3s 14ms/step\n",
            "182/182 [==============================] - 3s 15ms/step - loss: 0.2069 - accuracy: 0.9552\n",
            "Test Accuracy: 95.52%\n"
          ]
        }
      ],
      "source": [
        "X_test_sequences = tokenizer.texts_to_sequences(X_test.lemmaText)  \n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=700)  \n",
        "\n",
        "predictions = model.predict(X_test_padded)\n",
        "\n",
        "predicted_classes = predictions.argmax(axis=-1)\n",
        "\n",
        "\n",
        "class_probabilities = predictions\n",
        "\n",
        "\n",
        "accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Test Accuracy: {accuracy[1] * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdzeRYpWKk_t",
        "outputId": "06bbff86-3bb7-4dac-ec96-c63daa76882a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('LSTM_LastModel.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
